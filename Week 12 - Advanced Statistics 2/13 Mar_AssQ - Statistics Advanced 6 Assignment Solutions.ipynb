{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5677048-01a8-459c-b9a3-f51c7680f719",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f02cc-4075-4693-b1e9-805ef1298335",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of two or more groups to determine if there are significant differences between them. To use ANOVA effectively and ensure the validity of the results, certain assumptions must be met:\n",
    "\n",
    "1. Independence of Observations: The observations in each group should be independent of each other. In other words, the data points in one group should not be influenced by or related to the data points in another group.\n",
    "\n",
    "2. Normality: The data in each group should follow a normal distribution. Normality assumption ensures that the sampling distribution of the group means will also be approximately normal.\n",
    "\n",
    "3. Homogeneity of Variance: The variances of the groups should be approximately equal. Homogeneity of variance assumption is crucial as ANOVA is sensitive to unequal variances, and violations can lead to incorrect conclusions.\n",
    "\n",
    "4. Outliers should be absent: Outliers needs to be removed from the data.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "1. Outliers: Outliers in the data can lead to violations of normality assumption, especially if the sample size is small. Outliers can also impact the homogeneity of variance assumption.\n",
    "\n",
    "2. Skewed Data: If the data is heavily skewed, it may not follow a normal distribution, violating the normality assumption.\n",
    "\n",
    "3. Unequal Variances: When the variances of the groups are substantially different, the homogeneity of variance assumption is violated. This can lead to incorrect conclusions in ANOVA.\n",
    "\n",
    "4. Non-Independence: If the observations in one group are related or dependent on the observations in another group, the independence assumption is violated, and ANOVA results may not be valid.\n",
    "\n",
    "5. Small Sample Size: With small sample sizes, it becomes difficult to assess the normality and homogeneity of variance assumptions. In such cases, non-parametric alternatives may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617d9a-3b32-42ba-b726-ac3039a40826",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb2228-d421-4339-bf11-b4aad9312358",
   "metadata": {},
   "source": [
    "One-Way ANOVA: One-Way ANOVA is used when we have one categorical independent variable (also known as a factor) with two or more levels, and we want to compare the means of a continuous dependent variable across these levels. It helps us determine whether there are any significant differences among the means of the groups. For example, we could use One-Way ANOVA to compare the test scores of students from three different schools.\n",
    "\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when we have two categorical independent variables (factors) and one continuous dependent variable. It allows us to test the main effects of each factor as well as the interaction effect between the two factors on the dependent variable. Two-Way ANOVA is suitable when we want to investigate the combined effects of two factors on an outcome. For instance, we might use Two-Way ANOVA to examine the impact of both gender and educational level on job performance.\n",
    "\n",
    "Repeated Measures ANOVA: Repeated Measures ANOVA (also known as Within-Subjects ANOVA) is used when we have a single group of participants or subjects, and we measure the same dependent variable multiple times under different conditions. It is used when the same participants are measured across different treatments or time points. Repeated Measures ANOVA allows us to examine within-subject variations and to test the effects of the independent variable(s) on the dependent variable over time or under different conditions. For example, we might use Repeated Measures ANOVA to analyze the performance of participants on a memory task before and after receiving a treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c7a20-afb6-4d03-b5bd-3f228961e638",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee7f98-f2c3-4b1e-a4be-54963cfb11c9",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of breaking down the total variation observed in a dataset into different components. These components represent the variability due to different factors or sources of variation. In ANOVA, the total variance is split into two main parts: the variance between groups and the variance within groups. \n",
    "\n",
    "The partitioning of variance is important in ANOVA because this partitioning helps us understand how much of the total variability in the data can be attributed to differences between the groups (due to the independent variable) and how much is simply due to random variability within each group. By comparing these components, ANOVA allows us to determine if there are significant differences among the group means.\n",
    "\n",
    "There are three key components of variance in ANOVA:\n",
    "\n",
    "Between-Group Variance (SSB): It measures how much the group means differ from the overall grand mean.\n",
    "\n",
    "Within-Group Variance (SSW): It measures how much the individual data points within each group deviate from their group mean.\n",
    "\n",
    "Total Variance (SST): This is the overall variability in the data and is the sum of both the between-group variance and the within-group variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787698a6-4752-45c9-b114-626c7a03861a",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe7f42eb-381f-4e25-ae5b-875e1c194232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 778.9333333333333\n",
      "\n",
      "Explained Sum of Squares (SSE): 624.1333333333337\n",
      "\n",
      "Residual Sum of Squares (SSR): 154.7999999999996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data for three groups\n",
    "group1 = [15, 18, 21, 24, 19]\n",
    "group2 = [22, 26, 29, 32, 27]\n",
    "group3 = [30, 34, 37, 40, 35]\n",
    "\n",
    "# Organize data into a list of groups\n",
    "groups = [group1, group2, group3]\n",
    "\n",
    "# Step 3: Calculate the means and overall mean\n",
    "group_means = [np.mean(group) for group in groups]\n",
    "overall_mean = np.mean(np.concatenate(groups))\n",
    "\n",
    "# Step 4: Calculate the Total Sum of Squares (SST)\n",
    "SST = sum((x - overall_mean)**2 for group in groups for x in group)\n",
    "\n",
    "# Step 5: Calculate the Explained Sum of Squares (SSE)\n",
    "SSE = sum(len(group) * (mean - overall_mean)**2 for group, mean in zip(groups, group_means))\n",
    "\n",
    "# Step 6: Calculate the Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc957587-054e-455b-b2b9-fad31569fefc",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e95283-1d73-4e9b-84d0-055b5293cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Fertilizer: 4.3906514112478434e-13\n",
      "\n",
      "Main Effect of Watering: 0.08630952380952384\n",
      "\n",
      "Interaction Effect: 0.0333333333333321\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dataframe = pd.DataFrame({\n",
    "    'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "    'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "    'height': [14, 16, 15, 15, 16, 13, 12, 11, 14, \n",
    "               15, 16, 16, 17, 18, 14, 13, 14, 14, \n",
    "               14, 15, 16, 16, 17, 18, 14, 13, 14, \n",
    "               14, 14, 15]\n",
    "})\n",
    "\n",
    "# Step 3: Perform the two-way ANOVA analysis\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) + C(Fertilizer):C(Watering)', data=dataframe).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Step 4: Extract and interpret the main effects and interaction effect\n",
    "main_effect_fertilizer = anova_table.loc['C(Fertilizer)', 'sum_sq'] / anova_table.loc['C(Fertilizer)', 'df']\n",
    "main_effect_watering = anova_table.loc['C(Watering)', 'sum_sq'] / anova_table.loc['C(Watering)', 'df']\n",
    "interaction_effect = anova_table.loc['C(Fertilizer):C(Watering)', 'sum_sq'] / anova_table.loc['C(Fertilizer):C(Watering)', 'df']\n",
    "\n",
    "print(\"Main Effect of Fertilizer:\", main_effect_fertilizer)\n",
    "print(\"Main Effect of Watering:\", main_effect_watering)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a196db-7ce1-4ba6-b6e7-0565380e35bf",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "Main Effect of Fertilizer:\n",
    "The main effect of Fertilizer is an extremely small value of approximately 4.39e-13. This indicates that the impact of the 'Fertilizer' factor on the dependent variable 'height' is nearly negligible. The value being close to zero suggests that there is almost no systematic difference in the 'height' between the 'daily' and 'weekly' Fertilizer treatments.\n",
    "\n",
    "Main Effect of Watering:\n",
    "The main effect of Watering is approximately 0.0863. This value represents the average impact of the 'Watering' factor on the dependent variable 'height', considering all levels of the other factor (Fertilizer). It suggests that, on average, the difference in 'height' between the 'daily' and 'weekly' Watering treatments is about 0.0863 units. This difference might be statistically significant, depending on the sample size and variability of the data.\n",
    "\n",
    "Interaction Effect:\n",
    "The interaction effect between Fertilizer and Watering is approximately 0.0333. This value indicates whether the combined effect of Fertilizer and Watering on 'height' is significantly different from what would be expected by simply adding the individual effects of each factor. The small value suggests that there is only a slight interaction between the 'Fertilizer' and 'Watering' factors on the 'height'. The interaction effect might not be substantial, but it indicates that the combination of the two factors has a slightly different impact on the 'height' compared to their individual effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628cb26d-97da-414e-861e-677788346e11",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5989a-3f9d-48f6-9490-2f9f6f41e11f",
   "metadata": {},
   "source": [
    "F-statistic: The F-statistic is a ratio of the variance between the group means to the variance within the groups. In this case, given F-statistic of 5.23.\n",
    "\n",
    "p-value: The p-value represents the probability of obtaining the observed results (or more extreme results) under the assumption that the null hypothesis is true. In the context of a one-way ANOVA, the null hypothesis states that there are no significant differences between the group means.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "he obtained p-value (0.02) is less than the commonly used significance level of 0.05. This means that there is sufficient evidence to reject the null hypothesis and conclude that there are significant differences between at least two of the groups being compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe6a13-45f9-4424-b015-95fcdddb24c8",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7066027-0608-408d-b85d-20ffabfdca96",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is essential to ensure the validity and reliability of the analysis.\n",
    "\n",
    "1. Complete Case Analysis (Listwise Deletion):\n",
    "Approach: This method involves excluding any participant who has missing data on any of the variables being analyzed, resulting in using only complete cases for the analysis.\n",
    "Consequences: This approach can lead to a reduction in sample size, potentially reducing the statistical power of the analysis. It may introduce bias if the missing data are not missing completely at random (MCAR), and the excluded participants differ systematically from the included participants.\n",
    "\n",
    "2. Mean Imputation:\n",
    "Approach: Missing values are replaced with the mean value of the observed data for the corresponding variable.\n",
    "Consequences: Mean imputation can distort the distribution of the data and underestimate the standard deviation, leading to narrower confidence intervals.\n",
    "\n",
    "3. Last Observation Carried Forward (LOCF):\n",
    "Approach: Missing values are replaced with the last observed value for that participant in the repeated measures design.\n",
    "Consequences: LOCF assumes that the missing values remain constant over time, which might not be accurate. This approach can artificially reduce variability, leading to biased estimates and results that may not represent the true changes over time.\n",
    "\n",
    "4. Multiple Imputation:\n",
    "Approach: Multiple imputation involves creating multiple plausible imputed datasets based on statistical modeling, which account for the uncertainty of the missing values.\n",
    "Consequences: Multiple imputation provides more accurate estimates and standard errors compared to single imputation methods like mean imputation. \n",
    "\n",
    "5. Maximum Likelihood Estimation (MLE):\n",
    "Approach: MLE is a statistical method that estimates the model parameters while accounting for the missing data, assuming data are missing at random (MAR) or missing completely at random (MCAR).\n",
    "Consequences: MLE is a principled approach for handling missing data in repeated measures ANOVA. It provides valid and efficient estimates when the assumption of missing data mechanism (MAR or MCAR) is met.\n",
    "\n",
    "In summary, Multiple imputation and maximum likelihood estimation are generally preferred methods as they account for the uncertainty due to missing data and provide more valid and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35039f-d8fc-4039-8928-c2739ef9ca14",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ade9e-5768-44f2-9e1d-cc41da11d4eb",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant overall difference between groups, post-hoc tests are used to determine which specific group means differ significantly from each other. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) Test:\n",
    "Use: Tukey's HSD test is used to compare all possible pairs of group means. It is appropriate when the sample sizes are equal or approximately equal.\n",
    "Example: Suppose you conducted an ANOVA to compare the effectiveness of three different treatments on pain relief in patients. The ANOVA indicates a significant difference in pain relief among the treatments. Now, you want to know which specific pairs of treatments are significantly different from each other, and you can use Tukey's HSD test for this purpose.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "Use: The Bonferroni correction is a conservative method used to adjust the significance level for multiple comparisons. It is suitable when you have a small number of planned comparisons and you want to control the family-wise error rate.\n",
    "Example: In a study comparing the effectiveness of four different teaching methods on students' test scores, the ANOVA reveals a significant difference among the teaching methods. Now, you want to conduct multiple pairwise comparisons to identify which methods are significantly different. To control for the increased probability of Type I error due to multiple comparisons, you can use the Bonferroni correction.\n",
    "\n",
    "3. Scheffé Test:\n",
    "Use: The Scheffé test is used when the sample sizes are unequal or the assumption of equal variances is violated. It is more conservative but provides broader confidence intervals compared to Tukey's HSD test.\n",
    "Example: Let's say you conducted an ANOVA to analyze the effects of different dosages of a drug on blood pressure. The ANOVA shows a significant overall effect, and you want to conduct multiple pairwise comparisons to find out which dosages significantly differ from each other. If the sample sizes in each group are different, you can use the Scheffé test to handle the unequal variances.\n",
    "\n",
    "4. Dunnett's Test:\n",
    "Use: Dunnett's test is used when you have one control group and you want to compare all other groups to the control group.\n",
    "Example: In a clinical trial, you have a control group receiving a placebo and several experimental groups receiving different drug treatments. You conducted an ANOVA to assess if any of the drug treatments significantly differ from the placebo. Now, you can use Dunnett's test to compare each experimental group with the control group and identify which treatments show significant differences in the outcome variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88ae4f-2282-4b6d-ac35-246b03952108",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8b7fa2-32e1-418f-84bb-418ee04cbe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 314.77608168047493\n",
      "\n",
      "p-value: 1.4648990161663305e-40\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Weight loss data for each diet (A, B, and C)\n",
    "diet_A = [5.2, 3.8, 4.5, 6.1, 4.9, 5.5, 3.7, 4.1, 4.8, 5.3,\n",
    "          5.6, 4.7, 3.9, 5.0, 4.2, 5.3, 5.1, 5.4, 4.3, 4.6,\n",
    "          3.5, 4.9, 5.2, 4.3, 3.6, 4.2, 5.1, 4.8, 5.3, 4.6]\n",
    "\n",
    "diet_B = [3.1, 2.9, 1.8, 2.5, 2.3, 3.5, 2.7, 2.4, 2.9, 2.6,\n",
    "          2.8, 2.1, 2.6, 3.0, 2.4, 2.8, 2.3, 2.5, 2.7, 2.2,\n",
    "          2.9, 2.4, 2.7, 3.2, 2.5, 2.6, 2.3, 2.8, 2.2, 2.7]\n",
    "\n",
    "diet_C = [1.7, 0.9, 1.5, 1.2, 1.8, 2.0, 1.4, 1.3, 1.9, 2.3,\n",
    "          1.6, 2.1, 2.2, 1.1, 1.5, 1.7, 1.4, 2.0, 1.8, 2.2,\n",
    "          1.3, 1.6, 1.9, 1.2, 1.8, 1.5, 2.1, 2.0, 1.6, 2.2]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stats, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Output the results\n",
    "print(\"F-statistic:\", f_stats)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955a316-ed59-4985-aa77-030fd61aa46e",
   "metadata": {},
   "source": [
    "F-statistic: the F-statistic is quite large, indicating that there is substantial variability in weight loss between the three diets compared to the variability within each diet group.\n",
    "\n",
    "p-value: Given the very low p-value (much smaller than the common significance level of 0.05), we can confidently reject the null hypothesis, which states that there are no significant differences between the mean weight loss of the three diets (A, B, and C).\n",
    "\n",
    "Therefore, we can conclude that there are significant differences in weight loss between at least two of the three diets (A, B, and C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09deac86-7aba-4f12-aa89-d53cec576912",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7261fd49-615f-4296-8219-18f314d85b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df         F    PR(>F)\n",
      "\n",
      "Program              0.020667   2.0  0.008430  0.991609\n",
      "\n",
      "Experience           4.485333   1.0  3.659007  0.067772\n",
      "\n",
      "Program:Experience   0.092667   2.0  0.037797  0.962965\n",
      "\n",
      "Residual            29.420000  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (time to complete the task) with two factors: Software Program and Experience Level\n",
    "data = {\n",
    "    'Time': [12.5, 11.9, 10.8, 13.1, 12.3, 11.7, 10.5, 12.8, 11.6, 10.9,\n",
    "             14.0, 12.2, 11.5, 10.4, 12.7, 11.5, 10.2, 12.6, 11.8, 10.6,\n",
    "             13.8, 12.1, 11.2, 10.7, 13.2, 11.9, 10.3, 13.0, 11.3, 10.1],\n",
    "    'Program': ['A'] * 10 + ['B'] * 10 + ['C'] * 10,\n",
    "    'Experience': ['Novice'] * 5 + ['Experienced'] * 5 + ['Novice'] * 5 + ['Experienced'] * 5 + ['Novice'] * 5 + ['Experienced'] * 5\n",
    "}\n",
    "\n",
    "# Creating dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ Program + Experience + Program:Experience'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Output the results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955cd81a-284e-44aa-a403-650b7568ff44",
   "metadata": {},
   "source": [
    "1. Main Effect of Program:\n",
    "\n",
    "Sum of Squares (sum_sq): 0.020667\n",
    "Degrees of Freedom (df): 2.0\n",
    "F-statistic (F): 0.008430\n",
    "p-value (PR(>F)): 0.991609\n",
    "\n",
    "Interpretation: The p-value for the main effect of Program is 0.991609, which is much larger than the common significance level of 0.05. Therefore, we fail to reject the null hypothesis, indicating that there are no significant differences in the average time to complete the task among the three software programs (Program A, Program B, and Program C).\n",
    "\n",
    "2. Main Effect of Experience:\n",
    "\n",
    "Sum of Squares (sum_sq): 4.485333\n",
    "Degrees of Freedom (df): 1.0\n",
    "F-statistic (F): 3.659007\n",
    "p-value (PR(>F)): 0.067772\n",
    "\n",
    "Interpretation: The p-value for the main effect of Experience is 0.067772, which is slightly larger than the common significance level of 0.05. While the p-value is not highly significant, it is close to the threshold, suggesting that there might be a trend or a weak effect of Experience Level on the average time to complete the task. However, to claim a significant difference, more data or further investigation might be needed.\n",
    "\n",
    "3. MInteraction Effect between Program and Experience:\n",
    "\n",
    "Sum of Squares (sum_sq): 0.092667\n",
    "Degrees of Freedom (df): 2.0\n",
    "F-statistic (F): 0.037797\n",
    "p-value (PR(>F)): 0.962965\n",
    "\n",
    "Interpretation: The p-value for the interaction effect between Program and Experience is 0.962965, which is much larger than the common significance level of 0.05. Thus, we fail to reject the null hypothesis, indicating that there is no significant interaction between the Software Program and Experience Level in affecting the time to complete the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62428f4-3793-4a89-a22b-a3293cba2355",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795689db-d410-4199-8697-044a9ef56cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -7.08029669591487\n",
      "\n",
      "p-value: 1.9155499470082678e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Sample data for test scores in the control and experimental groups\n",
    "control_scores = [75, 82, 90, 78, 85, 77, 80, 83, 79, 81, 88, 86, 75, 78, 80, 82, 84, 77, 79, 85]\n",
    "experimental_scores = [88, 92, 96, 85, 90, 87, 89, 93, 91, 94, 86, 85, 90, 92, 88, 87, 85, 91, 89, 92]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stats, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Output the results of the t-test\n",
    "print(\"T-statistic:\", t_stats)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4800b0-1a01-43bf-951a-136246b15c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "\n",
      "=========================================================\n",
      "\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Control Experimental      8.3   0.0 5.9269 10.6731   True\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform post-hoc test (Tukey's HSD) if the t-test results are significant\n",
    "if p_value < 0.05:\n",
    "    data = pd.DataFrame({'Scores': control_scores + experimental_scores,\n",
    "                         'Group': ['Control'] * len(control_scores) + ['Experimental'] * len(experimental_scores)})\n",
    "    mc = MultiComparison(data['Scores'], data['Group'])\n",
    "    posthoc_result = mc.tukeyhsd()\n",
    "    print(posthoc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d00bf0-fd2e-4ca4-8404-2979ffb56ad4",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The \"meandiff\" column indicates the mean difference between the test scores of the two groups. In this case, the mean difference is 8.3.\n",
    "\n",
    "The \"p-adj\" column represents the adjusted p-value after performing multiple comparisons. The p-value is 0.0, which means the difference is highly significant.\n",
    "\n",
    "The \"lower\" and \"upper\" columns represent the lower and upper bounds of the confidence interval for the mean difference. The confidence interval ranges from 5.9269 to 10.6731, and it does not include zero, indicating a significant difference.\n",
    "\n",
    "The \"reject\" column shows whether the null hypothesis of no difference between the groups is rejected or not. Since the p-value is less than the chosen significance level (0.05), the \"reject\" column is marked as \"True,\" confirming that there is a significant difference between the Control and Experimental groups.\n",
    "\n",
    "In summary, based on the post-hoc test results, the new teaching method (Experimental group) has significantly higher test scores compared to the traditional teaching method (Control group). The Tukey's HSD test helps identify and confirm the specific groups that differ significantly from each other after obtaining a significant result in the initial two-sample t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574032a-ea94-42b8-b8b5-22ab11dc43c1",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a347e695-7676-4ac2-b4c8-ed63c71bfebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  6.3005 2.0000 58.0000 0.0033\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Sample data for daily sales in each store\n",
    "data = {\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Store': ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30,\n",
    "    'Sales': [100, 110, 105, 95, 115, 120, 105, 100, 110, 105,\n",
    "              200, 195, 210, 205, 190, 180, 200, 205, 190, 195,\n",
    "              150, 145, 155, 160, 170, 165, 175, 160, 150, 155,\n",
    "              120, 125, 130, 135, 140, 125, 130, 135, 140, 145,\n",
    "              90, 95, 100, 85, 80, 75, 95, 90, 85, 80,\n",
    "              104, 126, 153, 148, 171, 166, 141, 119, 177, 130, \n",
    "              195, 172, 127, 173, 154, 110, 176, 108, 138, 116, \n",
    "              128, 185, 155, 120, 183, 192, 141, 113, 108, 122,\n",
    "              110, 176, 108, 138, 116, 128, 185, 155, 120, 183],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "formula = 'Sales ~ Store + C(Day)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = AnovaRM(df, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Output the results of the repeated measures ANOVA\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "243945a1-75a4-47f4-9c3b-6298dbdc9ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store       Sales\n",
      "0  Store A  154.000000\n",
      "1  Store B  121.166667\n",
      "2  Store C  144.500000\n"
     ]
    }
   ],
   "source": [
    "# Perform post-hoc test (Tukey's HSD) if the ANOVA results are significant\n",
    "if anova_table.anova_table['Pr > F']['Store'] < 0.05:\n",
    "    posthoc_result = df.groupby('Store')['Sales'].mean().reset_index()\n",
    "    print(posthoc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7313346-a532-486d-a415-b03e90c82369",
   "metadata": {},
   "source": [
    "The ANOVA results indicate that there are significant differences in the average daily sales between the three stores. We can use the post-hoc test to compare the mean daily sales of each store against each other to identify which specific stores have significantly different sales. In this case, the average daily sales for Store A (154.00) are significantly different from Store B (121.17) and Store C (144.50). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434efa0a-5b7d-4427-8749-13650825aef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
